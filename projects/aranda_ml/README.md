# Multilayer Perceptron Classifier Aranda (MLflow & Spark) ğŸš€

Este proyecto implementa un **clasificador PerceptrÃ³n Multicapa (MLP)** utilizando **Spark ML y MLflow** para la gestiÃ³n de experimentos y seguimiento de modelos.

## ğŸ“Œ CaracterÃ­sticas
âœ… Implementa un **pipeline de preprocesamiento y modelado** con Spark ML.  
âœ… Utiliza **MLflow** para seguimiento de experimentos y almacenamiento de modelos.  
âœ… Usa **Databricks UC** como repositorio de modelos.  
âœ… Soporta mÃºltiples entornos de configuraciÃ³n a travÃ©s de **config/base.yaml**.

---

## ğŸ“‚ Estructura del Proyecto
```
ğŸ“¦ project_root/
 â”£ ğŸ“‚ config/
 â”ƒ â”— ğŸ“œ base.yaml                       # ConfiguraciÃ³n general del modelo y datos
 â”£ ğŸ“‚ notebooks/
 â”ƒ â”£ ğŸ“œ data_preparation.ipynb          # Preparar datos
 â”ƒ â”£ ğŸ“œ eda.ipynb                       # EDA
 â”ƒ â”£ ğŸ“œ test_evaluation.ipynb           # Test
 â”£ ğŸ“‚ utils/
 â”ƒ â”£ ğŸ“œ config.py                       # Carga de configuraciones YAML
 â”£ ğŸ“œ model.py                          # ImplementaciÃ³n del modelo MLP con MLflow y Spark
 â”£ ğŸ“œ README.md                         # DocumentaciÃ³n del proyecto
 â”£ ğŸ“œ requirements.txt                  # Dependencias necesarias
```

---

## ğŸ”§ Requisitos
Antes de ejecutar el proyecto, asegÃºrate de instalar las dependencias necesarias:

```bash
pip install -r requirements.txt
```

TambiÃ©n necesitarÃ¡s un entorno de **Apache Spark** y una configuraciÃ³n activa de **Databricks** si usas UC con ML.

---

## âš™ï¸ ConfiguraciÃ³n
El archivo `config/base.yaml` contiene los parÃ¡metros del modelo y la configuraciÃ³n del entorno. AquÃ­ un ejemplo:

```yaml
aranda:
  model_params:
    tol: 1e-6
    seed: 123
    layer: 100
    last_run: -1
    max_iter: 300
    vocab_size: 5000
    solver: "l-bfgs"
    step_size: 0.01
    first_element: 0
    splits: [0.76, 0.24]

  databricks:
    databricks_uc: "databricks-uc"

  dataset:
    description: "Este conjunto de datos contiene informaciÃ³n sobre incidentes de soporte, con campos como CategoryID_idx y su Description."

  experiment:
    name: "perceptron_classifier_experiment"

  environments:
    develop:
      catalog_name: "tmp_cat_dev"
      schema_name: "aranda_ml"
      table_name: "features"
      model_name: "perceptron_classifier"

    master:
      catalog_name: "tmp_cat_prod"
      schema_name: "aranda_ml"
      table_name: "features"
      model_name: "perceptron_classifier"
```

Puedes cambiar estos valores segÃºn sea necesario para ajustarlos a tu entorno.

---

## ğŸš€ Ejecutar el Entrenamiento
Para entrenar el modelo y registrarlo en MLflow, ejecuta:

```bash
python models/baseline.py
```

Esto:
1. CargarÃ¡ los datos desde Spark.
2. AplicarÃ¡ el preprocesamiento (tokenizaciÃ³n, eliminaciÃ³n de stopwords y vectorizaciÃ³n).
3. EntrenarÃ¡ un **PerceptrÃ³n Multicapa (MLP)** con los parÃ¡metros definidos en `config/base.yaml`.
4. EvaluarÃ¡ el modelo y guardarÃ¡ los resultados en MLflow.
5. RegistrarÃ¡ el mejor modelo en **Databricks UC** como "Champion".

---

## ğŸ“Š Seguimiento de Experimentos
Puedes visualizar los experimentos ejecutados con MLflow con:

```bash
mlflow ui
```

Esto abrirÃ¡ una interfaz web donde podrÃ¡s ver los experimentos, mÃ©tricas y modelos registrados.

---

## ğŸ“Œ Mejoras Futuras
ğŸ”¹ Soporte para mÃ¡s modelos de clasificaciÃ³n.  
ğŸ”¹ ImplementaciÃ³n de validaciÃ³n cruzada.  
ğŸ”¹ OptimizaciÃ³n automÃ¡tica de hiperparÃ¡metros.  

---
