{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "167676bd-5f53-4148-87ec-971f71caf3ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "#TODO : Config\n",
    "CATALOG_NAME =  \"tmp_cat_dev\"\n",
    "SCHEMA_NAME = \"aranda_ml\"\n",
    "MODEL_NAME = \"perceptron_classifier\"\n",
    "\n",
    "MODEL_FULL_NAME = f'{CATALOG_NAME}.{SCHEMA_NAME}.{MODEL_NAME}'\n",
    "\n",
    "CATALOG_NAME_PRD = \"tmp_cat_dev\"\n",
    "SCHEMA_NAME_PRD = \"aranda\"\n",
    "\n",
    "TARGET_MODEL_FULL_NAME = f'{CATALOG_NAME_PRD}.{SCHEMA_NAME_PRD}.{MODEL_NAME}'\n",
    "\n",
    "EXPERIMENT = \"perceptron_classifier_experiment\"\n",
    "LOCAL_DIR = \"/dbfs/FileStore/modelos\"\n",
    "UC = \"databricks-uc\"\n",
    "\n",
    "mlflow.set_registry_uri(UC)\n",
    "\n",
    "client = MlflowClient()\n",
    "models = client.search_model_versions(filter_string=f\"name='{MODEL_FULL_NAME}'\")\n",
    "\n",
    "best_model = None\n",
    "best_accuracy_score = float('-inf')\n",
    "\n",
    "for model in models:\n",
    "    run_id = model.run_id\n",
    "    run_data = client.get_run(run_id).data\n",
    "\n",
    "    if \"accuracy_score\" in run_data.metrics:\n",
    "        accuracy_score = run_data.metrics[\"accuracy_score\"]\n",
    "        if accuracy_score > best_accuracy_score:\n",
    "            best_accuracy_score = accuracy_score\n",
    "            best_model = model\n",
    "\n",
    "if best_model:\n",
    "    run_id = best_model.run_id\n",
    "    run_info = client.get_run(run_id)\n",
    "\n",
    "    new_model_version = mlflow.register_model(model_uri=f\"models:/{MODEL_FULL_NAME}/{best_model.version}\", name=TARGET_MODEL_FULL_NAME)\n",
    "    client.set_registered_model_alias(TARGET_MODEL_FULL_NAME, \"Champion\", new_model_version.version)\n",
    "   \n",
    "    experiment_name = f\"/{EXPERIMENT}\"\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    if run_info.info.artifact_uri:\n",
    "        artifact_uri = run_info.info.artifact_uri\n",
    "\n",
    "        if not os.path.exists(LOCAL_DIR):\n",
    "            os.mkdir(LOCAL_DIR)\n",
    "        local_path = client.download_artifacts(run_id, EXPERIMENT, LOCAL_DIR)\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_param(\"source_model\", MODEL_FULL_NAME)\n",
    "            mlflow.log_param(\"target_model\", TARGET_MODEL_FULL_NAME)\n",
    "            mlflow.log_metric(\"accuracy_score\", round(best_accuracy_score, 3))\n",
    "            mlflow.log_artifacts(local_path)\n",
    "\n",
    "        print(f\"Experimento registrado en MLflow: {experiment_name}\")\n",
    "else:\n",
    "    print(\"No se encuentra modelo.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "registry",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
